name: GraphAr Spark CI

on:
  # Trigger the workflow on push or pull request,
  # but only for the main branch
  push:
    branches:
      - main
    paths:
      - 'spark/**'
      - '.github/workflows/spark.yaml'
  pull_request:
    branches:
      - main
    paths:
      - 'spark/**'
      - '.github/workflows/spark.yaml'

concurrency:
  group: ${{ github.repository }}-${{ github.event.number || github.head_ref || github.sha }}-${{ github.workflow }}
  cancel-in-progress: true

jobs:
  GraphAr-spark:
    runs-on: ubuntu-20.04
    steps:
    - uses: actions/checkout@v3
      with:
          submodules: true

    - name: Code Format Check
      run: |
        export JAVA_HOME=${JAVA_HOME_11_X64}
        pushd spark
        mvn spotless:check
        popd

    - name: Build GraphAr Spark
      run: |
        export JAVA_HOME=${JAVA_HOME_11_X64}
        pushd spark
        mvn clean package -DskipTests -Dspotless.check.skip=true
        popd

    - name: Run test
      run: |
        export JAVA_HOME=${JAVA_HOME_11_X64}
        pushd spark
        mvn test -Dspotless.check.skip=true
        popd

    - name: Run Neo4j2GraphAr example
      run: |
        export JAVA_HOME=${JAVA_HOME_11_X64}
        pushd spark
        scripts/get-spark-to-home.sh
        export SPARK_HOME="${HOME}/spark-3.2.2-bin-hadoop3.2"
        export PATH="${SPARK_HOME}/bin":"${PATH}"

        scripts/get-neo4j-to-home.sh
        export NEO4J_HOME="${HOME}/neo4j-community-4.4.23"
        export PATH="${NEO4J_HOME}/bin":"${PATH}"
        neo4j-admin set-initial-password neo4j

        scripts/deploy-neo4j-movie-data.sh

        scripts/build.sh

        export NEO4J_USR="neo4j"
        export NEO4J_PWD="neo4j"
        scripts/run-neo4j2graphar.sh

        # clean the movie data and import from GraphAr
        echo "match (a) -[r] -> () delete a, r;match (a) delete a;" | cypher-shell -u ${NEO4J_USR} -p ${NEO4J_PWD} -d neo4j --format plain
        scripts/run-graphar2neo4j.sh

        # stop and clean
        popd
      
    - name: Run Nebula2GraphAr example
      run: |
        export JAVA_HOME=${JAVA_HOME_11_X64}
        pushd spark
        scripts/get-nebula-to-home.sh
        export SPARK_HOME="${HOME}/spark-3.2.2-bin-hadoop3.2"
        export PATH="${SPARK_HOME}/bin":"${PATH}"

        scripts/get-nebula-to-home.sh

        scripts/deploy-nebula-default-data.sh

        scripts/build.sh

        scripts/run-nebula2graphar.sh

        # clean the data
        docker run \
            --rm \
            -ti \
            --name nebula-console-loader \
            --network nebula-docker-env_nebula-net \
            vesoft/nebula-console:nightly -addr 172.28.3.1 -port 9669 -u root -p nebula -e "use basketballplayer; clear space basketballplayer;"
        
        # import from GraphAr
        scripts/run-graphar2nebula.sh

        # stop and clean
        popd
